# 例

不動産の価格は「部屋が広いほど価格は高くなる」「築年数が長いほど価格は安くなる」「最寄駅までの距離が遠いほど価格は安くなる」と考えられる

具体的に「部屋が1m^2広い」「築年数が1年長い」「最寄駅までの所要時間が1分多い」ことがどのくらい不動産の価格に影響すると言えるか分析する

# 重回帰式

`y = β0 + β1x1 + β2x2 + β3x3`

*y* 目的変数

*x1, x2, x3* 説明変数

*β0, β1, β2, β3* 偏回帰係数

偏回帰係数は「他の説明変数が一定という仮定の下で、ある説明変数が1だけ変化した時に目的変数がいくつ変化するか」を表す値

# サンプルデータ

[multiple_regression_sample.csv](https://github.com/krabben27/tokei-note/tree/master/%E5%9B%9E%E5%B8%B0%E5%88%86%E6%9E%90/multiple_regression_sample.csv)

*price* 価格 y（百万円）

*size* 広さ x1（m^2）

*year* 築年数 x2（年）

*minutes* 最寄り駅まで x3（分）

# コード

```r
df <- read.csv("multiple_regression_sample.csv", header=T, fileEncoding="utf-8", row.names=1)

# lm 線形モデルを用いた回帰分析
ans <- lm(df$price ~ df$size + df$year + df$minutes)

# 回帰係数以外の分析結果を取得する
s.ans <- summary(ans)

# 回帰係数を取得する
coe <- s.ans$coefficient

# dfの行数をカウントする
N <- nrow(df)

# AIC 赤池情報量規準
# 統計的モデルの予測性の良さを観測値と理論値の差（残差）を用いて評価する統計量
# 値が小さいほど当てはまりが良い
aic <- AIC(ans)

# 行数が同じ行列を結合して新しい行列を作る
result <- cbind(coe, aic, N)

# 2行目から最終行の5～6列目に空白を代入する
result[2:nrow(result), 5:6] <- ""

filename <- "multiple_regression_output.csv"

# 列名を出力する
# matrix 行列を作成する
# c ベクトルを作成する
# nrow 行数を返す
write.table(matrix(c("", colnames(result)), nrow=1), filename, append=T, quote=F, sep=",", row.names=F, col.names=F)

# 分析結果を出力する
write.table(result, filename, append=T, quote=F, sep=",", row.names=T, col.names=F)
```

結果（multiple_regression_output.csv）

```csv
,Estimate,Std. Error,t value,Pr(>|t|),aic,N
(Intercept),28.3274294562375,12.1428903110763,2.33284075953468,0.0330373126054696,152.001821371633,20
df$size,0.121434403898615,0.0374357356224622,3.24380974166704,0.00508683859238098,,
df$year,-0.556910561141962,0.262225618630711,-2.12378395387162,0.0496297015477267,,
df$minutes,-0.379092061784059,0.403381583668084,-0.939785248341899,0.361300164967447,,
```

TODO：決定係数や信頼区間はどうやって取得する？

## 出力結果の補足

||Estimate|Std. Error|t value|Pr(>\|t\|)|aic|N|
|--|--|--|--|--|--|--|
|価格 y（百万円）|28.327|12.142|2.332|0.033|152.001|20|
|広さ x1（m^2）|0.121|0.0374|3.243|0.005|||
|築年数 x2（年）|-0.556|0.262|-2.123|0.049|||
|最寄り駅まで x3（分）|-0.379|0.403|-0.939|0.361|||

**Estimate**

偏回帰係数（β0, β1, β2, β3）の推定値

**Std. Error**

各回帰係数の推定量の標準誤差

**t value**

t値

説明変数は目的変数に影響を与えない（回帰係数=0）という帰無仮説に対するt検定によって計算される値

計算式は `t = 回帰係数 / 標準誤差`

**Pr(>|t|)**

p値

`βi = 0` と仮定した場合に今回と同じかそれ以上に極端な結果が得られる確率

一般にp値が 0.05 よりも小さいと「統計的に有意」と言われる

β1のp値は0.005なので、もし `β1 = 0` だとしたら今回のような結果が得られる確率は0.5%しかない。つまり `β1 = 0` とは考えにくい

=> 帰無仮説を棄却できるので「部屋が広いほど不動産の価格は高くなる」と判断できる

※β1の推定値（0.121）がプラスなので「高くなる」かどうかを考える

一方、β3のp値は0.361なので、もし `β3 = 0` だとしたら今回のような結果が得られる確率は36.1%もある。つまり `β3 = 0` でもおかしくない

=> 帰無仮説を棄却できないので「最寄駅までの所要時間が長いほど不動産の価格は安くなる」とは言い切れない

※β3の推定値（-0.379）がマイナスなので「安くなる」かどうかを考える

**aic**

TODO

## 重回帰式の確認

```
y = 28.327 + 0.121x1 - 0.556x2 - 0.379x3
```

- 100m^2
- 築20年
- 最寄り駅まで15分

の物件の価格は

```
28.327 + (0.121*100) - (0.556*20) - (0.379*15)
= 23.622
```

2362.2万円と予測される

# 重回帰分析の注意点

仮に広さと築年数の相関係数が高い場合

※広くなると築年数が大きくなる、または狭くなると築年数が小さくなるようなケース

「他の説明変数が一定」という偏回帰係数の仮定が崩れ不可解な値が得られる可能性がある

このように説明変数どうしが強く相関しているせいで解析に支障が出る状態を **多重共線性（マルチコ）** と言う

---

参考

[重回帰分析とは。具体例から分かるエクセルでの重回帰分析のやり方とその解釈｜アタリマエ！](https://atarimae.biz/archives/18904)

[R言語で線形モデルによる回帰分析 | AVILEN AI Trend](https://to-kei.net/programming/r-beginner/r-3/)
